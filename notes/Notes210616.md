# Notes 210616

## Caching the statuses

"open-ended" call gives the _most recent_ statuses (optionally giving a limiting point by `since_id`).

We could stick to the default batch size of up to forty statuses.

 1. make one call (`since_id` could be set from most recent in cache)
 2. "fill in" the cache with the new statuses up to cached most-recent id
 3. determine whether we have both pairs. YES -> finish
 4. NO -> make subsequent call, where `max_id` is set, and continue with 2.
 
What do we need to cache? Ids seem strictly monotonically increasing. The data tuple is
(id, date, content, image-path). If we assume they are in a CSV or binary file, we could simply read that
entirely into memory, and rewrite the entire file when new data is available. Alternatively, the
file could be append-only actualised, then the entries would have to be sorted with ascending ids.

Say we run for 365 days, and there are still four statuses per day, and the contents is around 200 bytes each,
and another 100 bytes for path and id. Let's say an entry is 300 bytes in the cache. That would amount to
400 KB data at the end. But also, we do not have to keep the entire cache, we actually
can drop everything that is older than a month, so that reduces to around 40 KB. An image download is perhaps
500 KB, so they take up 60 MB per month, or 700 MB per year. We could thus just leave them on the 32 GB SD card
without the need to clean up.

